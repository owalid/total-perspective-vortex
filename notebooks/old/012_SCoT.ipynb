{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.frontiersin.org/articles/10.3389/fnhum.2016.00235/full\n",
    "\n",
    "https://www.mdpi.com/1424-8220/21/19/6570\n",
    "\n",
    "\n",
    "https://github.com/dokato/connectivipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Coherence Dirigée Partielle, ou PDC (Partial Directed Coherence en anglais), est une mesure de la connectivité dans le domaine de la neurophysiologie et de l'analyse du cerveau. Elle est utilisée pour étudier comment différentes régions du cerveau interagissent les unes avec les autres.\n",
    "\n",
    "La PDC est particulièrement utile pour comprendre comment l'activité électrique ou électroencéphalographique (EEG) est propagée entre différentes régions du cerveau. Voici quelques points clés pour comprendre la PDC :\n",
    "\n",
    "Connectivité Dirigée : La PDC permet de mesurer la direction de la connectivité entre les régions cérébrales. Autrement dit, elle indique comment l'activité d'une région du cerveau influence l'activité d'une autre région, et vice versa.\n",
    "\n",
    "Fréquences et Bandes de Fréquences : La PDC peut être calculée pour différentes fréquences ou bandes de fréquences du signal EEG. Cela permet de comprendre comment la connectivité entre les régions cérébrales varie en fonction de la fréquence.\n",
    "\n",
    "Utilisation : La PDC est largement utilisée dans la recherche en neurosciences pour étudier des phénomènes tels que la communication cérébrale, la synchronisation entre les régions cérébrales, et les changements dans la connectivité en réponse à des tâches spécifiques ou à des pathologies.\n",
    "\n",
    "Interprétation : Une PDC proche de 1 entre deux régions signifie une forte connectivité dirigée de l'une vers l'autre, tandis qu'une PDC proche de 0 indique une connectivité faible ou nulle.\n",
    "\n",
    "Applications : La PDC est utilisée dans divers domaines, y compris la recherche sur les troubles neurologiques, l'étude de la cognition humaine, la neurologie clinique, et même dans le domaine de l'analyse de l'activité cérébrale lors de tâches spécifiques telles que la réflexion ou la perception.\n",
    "\n",
    "En résumé, la PDC est une mesure importante pour comprendre comment différentes parties du cerveau interagissent et communiquent entre elles. Elle est souvent utilisée dans le cadre de la recherche en neurosciences pour mieux comprendre le fonctionnement du cerveau et les altérations qui peuvent survenir dans diverses conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.linalg import solve\n",
    "from scipy.signal import lfilter\n",
    "from scot.connectivity import Connectivity\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP, SPoC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mne.decoding import (\n",
    "    SlidingEstimator,\n",
    "    GeneralizingEstimator,\n",
    "    Scaler,\n",
    "    cross_val_multiscore,\n",
    "    LinearModel,\n",
    "    get_coef,\n",
    "    Vectorizer,\n",
    "    CSP,\n",
    ")\n",
    "import numpy as np\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import preprocess_data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Flatten, BatchNormalization, Conv2D, DepthwiseConv2D, AveragePooling2D, Activation, SeparableConv2D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils import preprocess_data\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "try:  # new in sklearn 0.19\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "except ImportError:\n",
    "    from sklearn.lda import LDA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scot\n",
    "import scot.xvschema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('../../files/S001/*.edf')\n",
    "'''\n",
    "=========  ===================================\n",
    "run        task\n",
    "=========  ===================================\n",
    "1          Baseline, eyes open\n",
    "2          Baseline, eyes closed\n",
    "3, 7, 11   Motor execution: left vs right hand\n",
    "4, 8, 12   Motor imagery: left vs right hand\n",
    "5, 9, 13   Motor execution: hands vs feet\n",
    "6, 10, 14  Motor imagery: hands vs feet\n",
    "=========  ===================================\n",
    "'''\n",
    "raws = []\n",
    "\n",
    "for i in [5, 9, 13]:\n",
    "    current_file = files[i]\n",
    "    r = read_raw_edf(current_file, preload=True, stim_channel='auto')\n",
    "    events, _ = mne.events_from_annotations(r)\n",
    "    if i in [5, 9, 13]:\n",
    "        new_labels_events = {1:'rest', 2:'action_hand', 3:'action_feet'} # action\n",
    "    new_annot = mne.annotations_from_events(events=events, event_desc=new_labels_events, sfreq=r.info['sfreq'], orig_time=r.info['meas_date'])\n",
    "    r.set_annotations(new_annot)\n",
    "    raws.append(r)\n",
    "    \n",
    "raw_obj = concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1057 samples (6.606 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 8 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['action_feet', 'action_hand', 'rest']\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 8.0 Hz\n",
      " lowpass: 40.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n",
      "{'action_feet': 1, 'action_hand': 2, 'rest': 3}\n",
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 10 components\n",
      "Fitting ICA took 0.9s.\n",
      "Using EOG channel: Fpz\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "No components to exclude\n",
      "Used Annotations descriptions: ['action_feet', 'action_hand']\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 721 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "raw = raw_obj.copy()\n",
    "\n",
    "# filters\n",
    "notch_freq = 60\n",
    "raw.notch_filter(notch_freq, fir_design='firwin')\n",
    "\n",
    "low_cutoff = 8\n",
    "high_cutoff = 40\n",
    "raw.filter(low_cutoff, high_cutoff, fir_design='firwin')\n",
    "\n",
    "events, event_dict = mne.events_from_annotations(raw)\n",
    "print(raw.info)\n",
    "print(event_dict)\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "eegbci.standardize(raw)\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw.set_montage(montage)\n",
    "\n",
    "## ICA\n",
    "n_components = 10\n",
    "ica = ICA(n_components=n_components, random_state=97, max_iter=800)\n",
    "ica.fit(raw)\n",
    "components_to_excludes, scores = ica.find_bads_eog(raw, ch_name='Fpz')\n",
    "if components_to_excludes is not None and len(components_to_excludes) > 0:\n",
    "    ica.exclude = components_to_excludes\n",
    "    raw = ica.apply(raw)\n",
    "else:\n",
    "    print(\"No components to exclude\")\n",
    "\n",
    "event_id = {'action_hand': 1, 'action_feet': 2}\n",
    "events, event_dict = mne.events_from_annotations(raw, event_id=event_id)\n",
    "tmin = -0.5  # Time before event in seconds\n",
    "tmax = 4.  # Time after event in seconds\n",
    "epochs = mne.Epochs(raw, events, event_dict, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 64, 721)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = scot.Workspace({'model_order': 30}, reducedim=3, fs=epochs.info['sfreq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.set_data(epochs.get_data(picks=picks), 'MEG', 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 45 but corresponding boolean dimension is 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s9/mx70pkk11bq2wl2cnrt6nfwc0000gn/T/ipykernel_53463/3241057533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_mvarica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# ws.get_connectivity('ffPDC')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/lib/python3.8/site-packages/scot/ooapi.py\u001b[0m in \u001b[0;36mdo_mvarica\u001b[0;34m(self, varfit)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MVARICA requires data to be set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         result = mvarica(x=self.data_[self.trial_mask_, :, :], cl=self.cl_[self.trial_mask_], var=self.var_,\n\u001b[0m\u001b[1;32m    227\u001b[0m                          reducedim=self.reducedim_, backend=self.backend_, varfit=varfit)\n\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixing_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 45 but corresponding boolean dimension is 1"
     ]
    }
   ],
   "source": [
    "ws.do_mvarica()\n",
    "# ws.get_connectivity('ffPDC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  672,     0,     2],\n",
       "       [ 2000,     0,     1],\n",
       "       [ 3328,     0,     1],\n",
       "       [ 4656,     0,     2],\n",
       "       [ 5984,     0,     2],\n",
       "       [ 7312,     0,     1],\n",
       "       [ 8640,     0,     1],\n",
       "       [ 9968,     0,     2],\n",
       "       [11296,     0,     1],\n",
       "       [12624,     0,     2],\n",
       "       [13952,     0,     2],\n",
       "       [15280,     0,     1],\n",
       "       [16608,     0,     1],\n",
       "       [17936,     0,     2],\n",
       "       [19264,     0,     1],\n",
       "       [20672,     0,     1],\n",
       "       [22000,     0,     2],\n",
       "       [23328,     0,     1],\n",
       "       [24656,     0,     2],\n",
       "       [25984,     0,     2],\n",
       "       [27312,     0,     1],\n",
       "       [28640,     0,     2],\n",
       "       [29968,     0,     1],\n",
       "       [31296,     0,     1],\n",
       "       [32624,     0,     2],\n",
       "       [33952,     0,     1],\n",
       "       [35280,     0,     2],\n",
       "       [36608,     0,     2],\n",
       "       [37936,     0,     1],\n",
       "       [39264,     0,     2],\n",
       "       [40672,     0,     1],\n",
       "       [42000,     0,     2],\n",
       "       [43328,     0,     1],\n",
       "       [44656,     0,     2],\n",
       "       [45984,     0,     2],\n",
       "       [47312,     0,     1],\n",
       "       [48640,     0,     1],\n",
       "       [49968,     0,     2],\n",
       "       [51296,     0,     1],\n",
       "       [52624,     0,     2],\n",
       "       [53952,     0,     1],\n",
       "       [55280,     0,     2],\n",
       "       [56608,     0,     2],\n",
       "       [57936,     0,     1],\n",
       "       [59264,     0,     1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "try:  # new in sklearn 0.19\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "except ImportError:\n",
    "    from sklearn.lda import LDA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scot\n",
    "import scot.xvschema\n",
    "import scotdata.motorimagery as midata\n",
    "\n",
    "raweeg = midata.eeg.T\n",
    "triggers = np.asarray(midata.triggers, dtype=int)\n",
    "classes = midata.classes\n",
    "fs = midata.samplerate\n",
    "locs = midata.locations\n",
    "locs = np.asarray(locs, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 187000), (180,), (180,), 100, (45, 3))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raweeg.shape, classes.shape, triggers.shape, fs, locs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1250,   2229,   3219,   4199,   5227,   6259,   7271,   8261,\n",
       "         9267,  10272,  11315,  12283,  13328,  14285,  15272,  16264,\n",
       "        17268,  18261,  19311,  20305,  21321,  22294,  23282,  24301,\n",
       "        25301,  26296,  27283,  28317,  29304,  30350,  32450,  33442,\n",
       "        34440,  35466,  36450,  37488,  38477,  39456,  40459,  41500,\n",
       "        42550,  43528,  44512,  45512,  46547,  47510,  48538,  49511,\n",
       "        50520,  51525,  52543,  53536,  54583,  55624,  56593,  57588,\n",
       "        58553,  59564,  60542,  61573,  63650,  64689,  65723,  66748,\n",
       "        67766,  68784,  69792,  70784,  71768,  72798,  73813,  74825,\n",
       "        75781,  76759,  77775,  78766,  79743,  80733,  81740,  82765,\n",
       "        83788,  84810,  85859,  86847,  87874,  88841,  89868,  90826,\n",
       "        91786,  92742,  94750,  95731,  96711,  97758,  98737,  99781,\n",
       "       100814, 101825, 102842, 103794, 104831, 105841, 106855, 107839,\n",
       "       108868, 109844, 110829, 111859, 112862, 113865, 114883, 115890,\n",
       "       116902, 117869, 118854, 119821, 120871, 121862, 122819, 123863,\n",
       "       125950, 126965, 127921, 128967, 130000, 131048, 132049, 133035,\n",
       "       133995, 134983, 135983, 136952, 137990, 138944, 139962, 140935,\n",
       "       141959, 142943, 143985, 144996, 146008, 146962, 148003, 148962,\n",
       "       149971, 150954, 151926, 152885, 153934, 154940, 157050, 158056,\n",
       "       159096, 160051, 161098, 162115, 163160, 164190, 165186, 166232,\n",
       "       167280, 168328, 169310, 170286, 171324, 172275, 173323, 174290,\n",
       "       175245, 176217, 177253, 178290, 179252, 180249, 181230, 182197,\n",
       "       183153, 184137, 185183, 186196])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KFold' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s9/mx70pkk11bq2wl2cnrt6nfwc0000gn/T/ipykernel_53463/3895995692.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mfold\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KFold' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set random seed for repeatable results\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# Switch backend to scikit-learn\n",
    "scot.backend.activate('sklearn')\n",
    "\n",
    "\n",
    "# Set up analysis object\n",
    "#\n",
    "# We simply choose a VAR model order of 30, and reduction to 4 components.\n",
    "ws = scot.Workspace({'model_order': 30}, reducedim=4, fs=fs)\n",
    "freq = np.linspace(0, fs, ws.nfft_)\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "#\n",
    "# Here we cut out segments from 3s to 4s after each trigger. This is right in\n",
    "# the middle of the motor imagery period.\n",
    "data = scot.datatools.cut_segments(raweeg, triggers, 3 * fs, 4 * fs)\n",
    "\n",
    "# Initialize cross-validation\n",
    "nfolds = 10\n",
    "kf = KFold(len(triggers))\n",
    "\n",
    "# LDA requires numeric class labels\n",
    "cl = np.unique(midata.classes)\n",
    "classids = np.array([dict(zip(cl, range(len(cl))))[c] for c in midata.classes])\n",
    "\n",
    "# Perform cross-validation\n",
    "lda = LDA()\n",
    "cm = np.zeros((2, 2))\n",
    "fold = 0\n",
    "for train, test in kf:\n",
    "    fold += 1\n",
    "\n",
    "    # Perform CSPVARICA\n",
    "    ws.set_data(data[train, :, :], classes[train])\n",
    "    ws.do_cspvarica()\n",
    "\n",
    "    # Find optimal regularization parameter for single-trial fitting\n",
    "    # ws.var_.xvschema = scot.xvschema.singletrial\n",
    "    # ws.optimize_var()\n",
    "    ws.var_.delta = 1\n",
    "\n",
    "    # Single-trial fitting and feature extraction\n",
    "    features = np.zeros((len(triggers), 32))\n",
    "    for t in range(len(triggers)):\n",
    "        print('Fold {:2d}/{:2d}, trial: {:d}   '.format(fold, nfolds, t),\n",
    "              end='\\r')\n",
    "        ws.set_data(data[t, :, :])\n",
    "        ws.fit_var()\n",
    "\n",
    "        con = ws.get_connectivity('ffPDC')\n",
    "\n",
    "        alpha = np.mean(con[:, :, np.logical_and(7 < freq, freq < 13)], axis=2)\n",
    "        beta = np.mean(con[:, :, np.logical_and(15 < freq, freq < 25)], axis=2)\n",
    "\n",
    "        features[t, :] = np.array([alpha, beta]).flatten()\n",
    "\n",
    "    lda.fit(features[train, :], classids[train])\n",
    "\n",
    "    acc_train = lda.score(features[train, :], classids[train])\n",
    "    acc_test = lda.score(features[test, :], classids[test])\n",
    "\n",
    "    print('Fold {:2d}/{:2d}, '\n",
    "          'acc train: {:.3f}, '\n",
    "          'acc test: {:.3f}'.format(fold, nfolds, acc_train, acc_test))\n",
    "\n",
    "    pred = lda.predict(features[test, :])\n",
    "    cm += confusion_matrix(classids[test], pred)\n",
    "\n",
    "print('\\nConfusion Matrix:\\n', cm)\n",
    "print('\\nTotal Accuracy: {:.3f}'.format(np.sum(np.diag(cm))/np.sum(cm)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
