{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 00:22:32.424046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.linalg import toeplitz\n",
    "from scipy.linalg import solve\n",
    "from scipy.signal import lfilter\n",
    "from scot.connectivity import Connectivity\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP, SPoC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mne.decoding import (\n",
    "    SlidingEstimator,\n",
    "    GeneralizingEstimator,\n",
    "    Scaler,\n",
    "    cross_val_multiscore,\n",
    "    LinearModel,\n",
    "    get_coef,\n",
    "    Vectorizer,\n",
    "    CSP,\n",
    ")\n",
    "import numpy as np\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import preprocess_data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Flatten, BatchNormalization, Conv2D, DepthwiseConv2D, AveragePooling2D, Activation, SeparableConv2D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils import preprocess_data\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "try:  # new in sklearn 0.19\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "except ImportError:\n",
    "    from sklearn.lda import LDA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_connectivity import spectral_connectivity_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import apply_inverse_epochs, read_inverse_operator\n",
    "from mne_connectivity import spectral_connectivity_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R13.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R09.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('../../files/S001/*.edf')\n",
    "'''\n",
    "=========  ===================================\n",
    "run        task\n",
    "=========  ===================================\n",
    "1          Baseline, eyes open\n",
    "2          Baseline, eyes closed\n",
    "3, 7, 11   Motor execution: left vs right hand\n",
    "4, 8, 12   Motor imagery: left vs right hand\n",
    "5, 9, 13   Motor execution: hands vs feet\n",
    "6, 10, 14  Motor imagery: hands vs feet\n",
    "=========  ===================================\n",
    "'''\n",
    "raws = []\n",
    "\n",
    "for i in [5, 9, 13]:\n",
    "    current_file = files[i]\n",
    "    r = read_raw_edf(current_file, preload=True, stim_channel='auto')\n",
    "    events, _ = mne.events_from_annotations(r)\n",
    "    if i in [5, 9, 13]:\n",
    "        new_labels_events = {1:'rest', 2:'action_hand', 3:'action_feet'} # action\n",
    "    new_annot = mne.annotations_from_events(events=events, event_desc=new_labels_events, sfreq=r.info['sfreq'], orig_time=r.info['meas_date'])\n",
    "    r.set_annotations(new_annot)\n",
    "    raws.append(r)\n",
    "    \n",
    "raw_obj = concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter from 59 - 61 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 59.35\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 59.10 Hz)\n",
      "- Upper passband edge: 60.65 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 60.90 Hz)\n",
      "- Filter length: 1057 samples (6.606 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 8 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 265 samples (1.656 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['action_feet', 'action_hand', 'rest']\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 8.0 Hz\n",
      " lowpass: 40.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n",
      "{'action_feet': 1, 'action_hand': 2, 'rest': 3}\n",
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 10 components\n",
      "Fitting ICA took 1.1s.\n",
      "Using EOG channel: Fpz\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "No components to exclude\n",
      "Used Annotations descriptions: ['action_feet', 'action_hand']\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 721 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "raw = raw_obj.copy()\n",
    "\n",
    "# filters\n",
    "notch_freq = 60\n",
    "raw.notch_filter(notch_freq, fir_design='firwin')\n",
    "\n",
    "low_cutoff = 8\n",
    "high_cutoff = 40\n",
    "raw.filter(low_cutoff, high_cutoff, fir_design='firwin')\n",
    "\n",
    "events, event_dict = mne.events_from_annotations(raw)\n",
    "print(raw.info)\n",
    "print(event_dict)\n",
    "picks = mne.pick_types(raw.info, meg=True, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "eegbci.standardize(raw)\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "raw.set_montage(montage)\n",
    "\n",
    "## ICA\n",
    "n_components = 10\n",
    "ica = ICA(n_components=n_components, random_state=97, max_iter=800)\n",
    "ica.fit(raw)\n",
    "components_to_excludes, scores = ica.find_bads_eog(raw, ch_name='Fpz')\n",
    "if components_to_excludes is not None and len(components_to_excludes) > 0:\n",
    "    ica.exclude = components_to_excludes\n",
    "    raw = ica.apply(raw)\n",
    "else:\n",
    "    print(\"No components to exclude\")\n",
    "\n",
    "event_id = {'action_hand': 1, 'action_feet': 2}\n",
    "events, event_dict = mne.events_from_annotations(raw, event_id=event_id)\n",
    "tmin = -0.5  # Time before event in seconds\n",
    "tmax = 4.  # Time after event in seconds\n",
    "epochs = mne.Epochs(raw, events, event_dict, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing metadata with 3 columns\n",
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 2016 connections\n",
      "    using t=0.000s..4.000s for estimation (641 points)\n",
      "    frequencies: 4.2Hz..9.0Hz (20 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: PLI\n",
      "    computing cross-spectral density for epoch 1\n",
      "    computing cross-spectral density for epoch 2\n",
      "    computing cross-spectral density for epoch 3\n",
      "    computing cross-spectral density for epoch 4\n",
      "    computing cross-spectral density for epoch 5\n",
      "    computing cross-spectral density for epoch 6\n",
      "    computing cross-spectral density for epoch 7\n",
      "    computing cross-spectral density for epoch 8\n",
      "    computing cross-spectral density for epoch 9\n",
      "    computing cross-spectral density for epoch 10\n",
      "    computing cross-spectral density for epoch 11\n",
      "    computing cross-spectral density for epoch 12\n",
      "    computing cross-spectral density for epoch 13\n",
      "    computing cross-spectral density for epoch 14\n",
      "    computing cross-spectral density for epoch 15\n",
      "    computing cross-spectral density for epoch 16\n",
      "    computing cross-spectral density for epoch 17\n",
      "    computing cross-spectral density for epoch 18\n",
      "    computing cross-spectral density for epoch 19\n",
      "    computing cross-spectral density for epoch 20\n",
      "    computing cross-spectral density for epoch 21\n",
      "    computing cross-spectral density for epoch 22\n",
      "    computing cross-spectral density for epoch 23\n",
      "    computing cross-spectral density for epoch 24\n",
      "    computing cross-spectral density for epoch 25\n",
      "    computing cross-spectral density for epoch 26\n",
      "    computing cross-spectral density for epoch 27\n",
      "    computing cross-spectral density for epoch 28\n",
      "    computing cross-spectral density for epoch 29\n",
      "    computing cross-spectral density for epoch 30\n",
      "    computing cross-spectral density for epoch 31\n",
      "    computing cross-spectral density for epoch 32\n",
      "    computing cross-spectral density for epoch 33\n",
      "    computing cross-spectral density for epoch 34\n",
      "    computing cross-spectral density for epoch 35\n",
      "    computing cross-spectral density for epoch 36\n",
      "    computing cross-spectral density for epoch 37\n",
      "    computing cross-spectral density for epoch 38\n",
      "    computing cross-spectral density for epoch 39\n",
      "    computing cross-spectral density for epoch 40\n",
      "    computing cross-spectral density for epoch 41\n",
      "    computing cross-spectral density for epoch 42\n",
      "    computing cross-spectral density for epoch 43\n",
      "    computing cross-spectral density for epoch 44\n",
      "    computing cross-spectral density for epoch 45\n",
      "    assembling connectivity matrix\n",
      "[Connectivity computation done]\n"
     ]
    }
   ],
   "source": [
    "# Compute connectivity for band containing the evoked response.\n",
    "# We exclude the baseline period:\n",
    "fmin, fmax = 4., 9.\n",
    "sfreq = raw.info['sfreq']  # the sampling frequency\n",
    "tmin = 0.0  # exclude the baseline period\n",
    "# epochs.load_data().pick_types(meg='grad')  # just keep MEG and no EOG now\n",
    "con = spectral_connectivity_epochs(\n",
    "    epochs, method='pli', mode='multitaper', sfreq=sfreq, fmin=fmin, fmax=fmax,\n",
    "    faverage=True, tmin=tmin, mt_adaptive=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.07777778],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.08222222],\n",
       "        [0.11333333],\n",
       "        [0.        ],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.13777778],\n",
       "        [0.08888889],\n",
       "        [0.10666667],\n",
       "        ...,\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.11777778],\n",
       "        [0.10888889],\n",
       "        [0.11777778],\n",
       "        ...,\n",
       "        [0.10444444],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.1       ],\n",
       "        [0.11111111],\n",
       "        [0.09777778],\n",
       "        ...,\n",
       "        [0.13777778],\n",
       "        [0.19111111],\n",
       "        [0.        ]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.get_data(output='dense')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
