{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "from pywt import wavedec\n",
    "from scipy.signal import welch\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mne_features.univariate import compute_spect_entropy, compute_wavelet_coef_energy\n",
    "# https://mne.tools/mne-features/api.html\n",
    "\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from mne.decoding import CSP, SPoC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from mne.decoding import (\n",
    "    SlidingEstimator,\n",
    "    GeneralizingEstimator,\n",
    "    Scaler,\n",
    "    cross_val_multiscore,\n",
    "    LinearModel,\n",
    "    get_coef,\n",
    "    Vectorizer,\n",
    "    CSP,\n",
    ")\n",
    "import numpy as np\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from utils import preprocess_data\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Dropout, Flatten, BatchNormalization, Conv2D, DepthwiseConv2D, AveragePooling2D, Activation, SeparableConv2D, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import mne\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import glob\n",
    "import numpy as np\n",
    "from utils import preprocess_data\n",
    "from mne.preprocessing import ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/ftp/arxiv/papers/1312/1312.2877.pdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "After the AAR process, the continuous EEG data were\n",
    "epoched by extracting data epochs that are time locked to\n",
    "specific event types.\n",
    "When no sensory inputs or motor outputs are being\n",
    "processed, the mu (8–12 Hz) and beta (13–30 Hz) rhythms are\n",
    "said to be synchronized [4, 27]. These rhythms are\n",
    "electrophysiological features that are associated with the\n",
    "brain’s normal motor output channels [4, 27]. While preparing\n",
    "for a movement or executing a movement, a desynchronization\n",
    "of the mu and beta rhythms occurs which is referred to as ERD\n",
    "and it can be extracted 1-2 seconds before onset of movement\n",
    "(as depicted in Fig. 4). Later, these rhythms synchronize again\n",
    "within 1-2 seconds after movement, and this is referred to as\n",
    "ERS.\n",
    "On the other hand, delta rhythms can be extracted from the\n",
    "motor cortex, within the pre-movement stage, and this is\n",
    "referred to MRCP. The slow (less than 3 Hz) MRCP is\n",
    "associated with an event-related negativity that occurs 1-2\n",
    "seconds before the onset of movement [28, 29].\n",
    "In our experiments, we extracted time-locking events with\n",
    "type = 3 (left hand) or type = 4 (right hand) with different\n",
    "epoch limits and types of analysis:\n",
    "- ERD analysis: epoch limits from -2 to 0 seconds.\n",
    "- ERS analysis: epoch limits from 4.1 to 5.1 seconds.\n",
    "- MRCP analysis: epoch limits from -2 to 0 seconds.\n",
    "\n",
    "Independent Component Analysis (ICA)\n",
    "After the AAR process, ICA was used to parse the\n",
    "underlying electrocortical sources from EEG signals that are\n",
    "affected by artifacts [30, 31]. Data decomposition using ICA\n",
    "changes the basis linearly from data that are collected at single\n",
    "scalp channels to a spatially transformed virtual channel basis.\n",
    "Each row of the EEG data in the original scalp channel data\n",
    "represents the time course of accumulated differences between\n",
    "source projections to a single data channel and one or more\n",
    "reference channels [32].\n",
    "EEGLAB was used to run ICA on the described epoched\n",
    "datasets (left and right ERD, ERS, and MRCP) for the channels\n",
    "FC3, FCZ, FC4, C3, C1, CZ, C2, and C4.\n",
    "F. Rhythm Isolation\n",
    "A short IIR band pass filter from 8 to 30 Hz was applied on\n",
    "the ERD/ERS epoched datasets of the experiment for the\n",
    "purpose of isolating mu/beta rhythms. Another short IIR\n",
    "lowpass filter of 3 Hz was applied on MRCP epoched datasets\n",
    "for isolating delta rhythms. The result of this was 6 files for\n",
    "each run: ERD/ERS and MRCP for both left and right hand\n",
    "movements for each subject.\n",
    "V. PRACTICAL IMPLEMENTATION AND RESULTS\n",
    "A. Feature Vectors Construction and Numerical\n",
    "Representation\n",
    "After the EEG datasets were analyzed as described in the\n",
    "previous section, the activation vectors were calculated for\n",
    "each of the resulted epochs’ datasets as the multiplication of the\n",
    "ICA weights and ICA sphere for each dataset subtracting the\n",
    "mean of the raw data from the multiplication results.\n",
    "Then, the mean, power, and energy of the activations were\n",
    "calculated to construct the feature vectors. For each subject’s\n",
    "single run, 6 feature vectors were extracted as <Power (8\n",
    "features), Mean (8 features), Energy (8 features), Type (1\n",
    "feature: ERS/ERD/MRCP), Side (1 target: Left/Right)>\n",
    "resulting in a 10826 feature matrix.\n",
    "The constructed features were represented in a numerical\n",
    "format that is suitable for use with machine learning algorithms\n",
    "[33, 34]. Every column in the features matrices was normalized\n",
    "between 0.1 and 0.9 such that the datasets could be inputted to\n",
    "the learning algorithms described in the next subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R11.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "9\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Used Annotations descriptions: ['T0', 'T1', 'T2']\n",
      "13\n",
      "Extracting EDF parameters from /Users/owalid/42/post_intership/total-perspective-vortex/files/S001/S001R02.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9759  =      0.000 ...    60.994 secs...\n",
      "Used Annotations descriptions: ['T0']\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('../files/S001/*.edf')\n",
    "\n",
    "'''\n",
    "https://github.com/mne-tools/mne-python/blob/main/mne/datasets/eegbci/eegbci.py#L110\n",
    "=========  ===================================\n",
    "run        task\n",
    "=========  ===================================\n",
    "1          Baseline, eyes open\n",
    "2          Baseline, eyes closed\n",
    "3, 7, 11   Motor execution: left vs right hand\n",
    "4, 8, 12   Motor imagery: left vs right hand\n",
    "5, 9, 13   Motor execution: hands vs feet\n",
    "6, 10, 14  Motor imagery: hands vs feet\n",
    "=========  ===================================\n",
    "'''\n",
    "raws = []\n",
    "f = [5,9,13]\n",
    "# ,6,10,14]\n",
    "for i in f:\n",
    "    print(i)\n",
    "    current_file = files[i-1]\n",
    "    r = read_raw_edf(current_file, preload=True, stim_channel='auto')\n",
    "    events, _ = mne.events_from_annotations(r)\n",
    "    if i in [5, 9, 13]:\n",
    "        new_labels_events = {1:'rest', 2:'action_hand', 3:'action_feet'} # action\n",
    "    else:\n",
    "        new_labels_events = {1:'rest', 2:'imagine_hand', 3:'imagine_feet'} # imagine\n",
    "    new_annot = mne.annotations_from_events(events=events, event_desc=new_labels_events, sfreq=r.info['sfreq'], orig_time=r.info['meas_date'])\n",
    "    r.set_annotations(new_annot)\n",
    "    raws.append(r)\n",
    "    \n",
    "raw_obj = concatenate_raws(raws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filter length: 1057 samples (6.606 sec)\n",
      "\n",
      "Filtering raw data in 3 contiguous segments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 0.5 - 79 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 79.00 Hz\n",
      "- Upper transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 79.50 Hz)\n",
      "- Filter length: 1057 samples (6.606 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['action_feet', 'action_hand', 'rest']\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fc5., Fc3., Fc1., Fcz., Fc2., Fc4., Fc6., C5.., C3.., C1.., ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.5 Hz\n",
      " lowpass: 79.0 Hz\n",
      " meas_date: 2009-08-12 16:15:00 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 160.0 Hz\n",
      ">\n",
      "{'action_feet': 1, 'action_hand': 2, 'rest': 3}\n",
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 10 components\n",
      "Fitting ICA took 0.6s.\n",
      "Using EOG channel: Fpz\n",
      "... filtering ICA sources\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "... filtering target\n",
      "Setting up band-pass filter from 1 - 10 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a two-pass forward and reverse, zero-phase, non-causal bandpass filter:\n",
      "- Windowed frequency-domain design (firwin2) method\n",
      "- Hann window\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 0.75 Hz)\n",
      "- Upper passband edge: 10.00 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-12 dB cutoff frequency: 10.25 Hz)\n",
      "- Filter length: 1600 samples (10.000 sec)\n",
      "\n",
      "No components to exclude\n",
      "Used Annotations descriptions: ['action_feet', 'action_hand']\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 30 events and 977 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "30 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "original_raw = raw_obj.copy()\n",
    "\n",
    "# filters\n",
    "notch_freq = 50\n",
    "original_raw.notch_filter(notch_freq, fir_design='firwin')\n",
    "\n",
    "low_cutoff = 0.5\n",
    "high_cutoff = 79\n",
    "original_raw.filter(low_cutoff, high_cutoff, fir_design='firwin')\n",
    "\n",
    "events, event_dict = mne.events_from_annotations(original_raw)\n",
    "print(original_raw.info)\n",
    "print(event_dict)\n",
    "picks = mne.pick_types(original_raw.info, meg=True, eeg=True, stim=False, eog=False, exclude='bads')\n",
    "eegbci.standardize(original_raw)\n",
    "montage = mne.channels.make_standard_montage('standard_1005')\n",
    "original_raw.set_montage(montage)\n",
    "\n",
    "## ICA\n",
    "n_components = 10\n",
    "ica = ICA(n_components=n_components, random_state=97, max_iter=800)\n",
    "ica.fit(original_raw)\n",
    "components_to_excludes, scores = ica.find_bads_eog(original_raw, ch_name='Fpz')\n",
    "if components_to_excludes is not None and len(components_to_excludes) > 0:\n",
    "    ica.exclude = components_to_excludes\n",
    "    original_raw = ica.apply(original_raw)\n",
    "else:\n",
    "    print(\"No components to exclude\")\n",
    "\n",
    "event_id = {'action_hand': 1, 'action_feet': 2}\n",
    "events, event_dict = mne.events_from_annotations(original_raw, event_id=event_id)\n",
    "tmin = -2  # Time before event in seconds\n",
    "tmax = 4  # Time after event in seconds\n",
    "epochs = mne.Epochs(original_raw, events, event_dict, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)\n",
    "\n",
    "\n",
    "# ERD analysis\n",
    "erd_epochs = mne.Epochs(original_raw, events, event_id=event_id, tmin=-2, tmax=0, baseline=None)\n",
    "\n",
    "# ERS analysis\n",
    "ers_epochs = mne.Epochs(original_raw, events, event_id=event_id, tmin=4.1, tmax=5.1, baseline=None)\n",
    "\n",
    "# MRCP analysis\n",
    "mrcp_epochs = mne.Epochs(original_raw, events, event_id=event_id, tmin=-2, tmax=0, baseline=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 30 events and 321 original time points ...\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    }
   ],
   "source": [
    "from mne.time_frequency import psd_multitaper\n",
    "\n",
    "spectrum = erd_epochs.compute_psd(method=\"multitaper\", fmin=8, fmax=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 64, 44)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectrum.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 15 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "# Define the wavelet decomposition parameters\n",
    "wavelet = 'db10'  # Choose a wavelet (e.g., 'morl')\n",
    "level = 15  # Adjust the decomposition level as needed\n",
    "\n",
    "# Perform wavelet decomposition on EEG data\n",
    "coeffs = pywt.wavedec(spectrum.get_data(), wavelet, level=level)\n",
    "mu_rhythm = coeffs[level][0] # Mu rhythm (8-13 Hz)\n",
    "beta_rhythm = coeffs[level][1]  # Beta rhythm (13-30 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "mean_mu = np.mean(mu_rhythm, axis=1)\n",
    "mean_beta = np.mean(beta_rhythm, axis=1)\n",
    "print(mean_mu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Using data from preloaded Raw for 30 events and 321 original time points ...\n",
      "0 bad epochs dropped\n",
      "Selecting by number: 10 components\n",
      "Using data from preloaded Raw for 30 events and 321 original time points ...\n",
      "Fitting ICA took 0.2s.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Method</th>\n",
       "        <td>fastica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Fit</th>\n",
       "        <td>14 iterations on epochs (9630 samples)</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>ICA components</th>\n",
       "        <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Available PCA components</th>\n",
       "        <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Channel types</th>\n",
       "        <td>eeg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ICA components marked for exclusion</th>\n",
       "        <td>&mdash;</td>\n",
       "    </tr>\n",
       "    \n",
       "</table>"
      ],
      "text/plain": [
       "<ICA | epochs decomposition, method: fastica (fit in 14 iterations on 9630 samples), 10 ICA components (64 PCA components available), channel types: eeg, no sources marked for exclusion>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 10\n",
    "ica = ICA(n_components=n_components, random_state=97, max_iter=800)\n",
    "ica.fit(mrcp_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_weights = ica.get_components()\n",
    "whitening_matrix = ica.get_components()\n",
    "\n",
    "# Calculate the whitening and sphering transformation matrix\n",
    "ica_sphere = np.linalg.pinv(np.dot(whitening_matrix, ica_weights.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = []\n",
    "ii = 0\n",
    "for epoch_data in epochs:\n",
    "    mean_value = np.mean(epoch_data, axis=1)\n",
    "    std_value = np.std(epoch_data, axis=1)\n",
    "    energy_value = np.sum(np.square(epoch_data), axis=1)\n",
    "    power_value = np.mean(np.square(epoch_data), axis=1)\n",
    "    epoch_features = np.hstack([std_value, mean_value, energy_value, power_value, mean_mu[ii], mean_beta[ii]])\n",
    "    feature_matrix.append(epoch_features)\n",
    "    ii += 1\n",
    "\n",
    "feature_matrix = np.array(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 258)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix.shape)\n",
    "# 192 = 64 channels * 3 features (mean, power, energy) + 2 features (mu, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.7507587602582318)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize feature_matrix with min-max normalization\n",
    "from sklearn import preprocessing\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "feature_matrix = min_max_scaler.fit_transform(feature_matrix)\n",
    "min(feature_matrix[0]), max(feature_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example labels (replace with your actual labels)\n",
    "labels = epochs.events[:, -1] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30,), (30, 258))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape, feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_matrix, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create and train the Naive Bayes classifier\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels on the test set\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "print(f'Naive Bayes Accuracy: {nb_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create and train the ANN classifier\n",
    "ann_classifier = MLPClassifier(hidden_layer_sizes=(5), max_iter=5800, activation='relu', random_state=42)\n",
    "ann_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels on the test set\n",
    "ann_predictions = ann_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ann_accuracy = accuracy_score(y_test, ann_predictions)\n",
    "print(f'ANN Accuracy: {ann_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/owalid/.pyenv/versions/3.8.12/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boosting\n",
      "Best Parameters: {'model__n_estimators': 50}\n",
      "Best Cross-Validated Accuracy: 0.45\n",
      "\n",
      "\n",
      "Model: Linear discriminant analysis\n",
      "Best Parameters: {'model__solver': 'svd', 'model__tol': 0.0001}\n",
      "Best Cross-Validated Accuracy: 0.57\n",
      "\n",
      "\n",
      "Model: SVM\n",
      "Best Parameters: {'model__C': 3, 'model__degree': 1, 'model__gamma': 3, 'model__kernel': 'linear'}\n",
      "Best Cross-Validated Accuracy: 0.63\n",
      "\n",
      "\n",
      "Model: KNN\n",
      "Best Parameters: {'model__n_neighbors': 4}\n",
      "Best Cross-Validated Accuracy: 0.48\n",
      "\n",
      "\n",
      "Model: MLP\n",
      "Best Parameters: {'model__hidden_layer_sizes': (100, 50), 'model__max_iter': 5000}\n",
      "Best Cross-Validated Accuracy: 0.55\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Best Parameters: {'model__max_depth': 100}\n",
      "Best Cross-Validated Accuracy: 0.55\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shuffle_split = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "models = [\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(), {'model__n_estimators': [50, 100]}),\n",
    "    ('Linear discriminant analysis', LinearDiscriminantAnalysis(), {'model__solver': ['svd'], 'model__tol': [0.0001, 0.00001]}),   \n",
    "    ('SVM', SVC(), {'model__C': [0.5, 1, 3, 5, 10], 'model__gamma': [3, 4, 5, 10], 'model__degree': [1, 3, 5, 8], 'model__kernel': ['linear']}),\n",
    "    ('KNN', KNeighborsClassifier(), {'model__n_neighbors': [4,5,6]}),\n",
    "    ('MLP', MLPClassifier(), {'model__hidden_layer_sizes': [(100, 50), (200, 100)],  'model__max_iter': [5000]}),\n",
    "    ('Decision Tree', DecisionTreeClassifier(), {'model__max_depth': [50, 100]}),\n",
    "]\n",
    "\n",
    "pipelines = []\n",
    "# csp = CSP()\n",
    "for name, model, param_grid in models:\n",
    "    pipeline = Pipeline([\n",
    "        # ('csp', csp),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    # param_grid['csp__n_components'] = [5, 10, 15]\n",
    "    pipelines.append((name, pipeline, param_grid))\n",
    "\n",
    "\n",
    "results = []\n",
    "for name, pipeline, param_grid in pipelines:\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=shuffle_split, n_jobs=-1)\n",
    "    grid_search.fit(feature_matrix, labels)\n",
    "    results.append((name, grid_search))\n",
    "\n",
    "\n",
    "res_grid = []\n",
    "for name, grid_search in results:\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best Cross-Validated Accuracy: {grid_search.best_score_:.2f}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
